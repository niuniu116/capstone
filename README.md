# Basic architecture of the model for cnn+lstm
![image](https://github.com/user-attachments/assets/d9f1b35e-096f-4aa7-aab2-4cba75638dcd)
# Reference:
AN IMAGE IS WORTH 16X16 WORDS:TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE.
https://arxiv.org/pdf/2010.11929/1000

Not All Tokens Are Equal: Human-centric Visual Analysis via Token Clustering Transformer
https://arxiv.org/abs/2204.08680

TCFormer: Visual Recognition via Token Clustering Transformer
https://arxiv.org/abs/2407.11321

Gated attention-enhanced vision transformer for small-sample uterine ultrasound image classification of atypical endometrial hyperplasia and endometrial cancer
https://www.sciencedirect.com/science/article/pii/S0141938225000812

Attention U-Net: Learning Where to Look for the Pancreas
https://arxiv.org/abs/1804.03999

Attention-Gated Networks for Improving Ultrasound Scan Plane Detection
https://arxiv.org/abs/1804.05338

SonoNet: Real-Time Detection and Localisation of Fetal Standard Scan Planes in Freehand Ultrasound
https://ieeexplore.ieee.org/document/7974824

Attention Map Guided Transformer Pruning for Edge Device
https://arxiv.org/abs/2304.01452
github:https://github.com/NUST-Machine-Intelligence-Laboratory/AMG

Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization
https://arxiv.org/abs/1610.02391
For linux: https://github.com/ramprs/grad-cam/
For pytorch: https://github.com/jacobgil/pytorch-grad-cam


![image](https://github.com/user-attachments/assets/c3596adb-eb18-4fdb-83f0-e5588ea22138)















